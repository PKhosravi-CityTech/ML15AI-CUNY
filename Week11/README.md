# ðŸ“Œ Week 11: Transformers & LLMs

## ðŸŽ¯ Learning Objectives

In this session, we will cover:

âœ… **Limitations of RNNs** â€“ Why traditional sequence models fall short.

âœ… **Self-Attention & Transformers** â€“ The key innovation behind modern deep learning.

âœ… **Understanding BERT** â€“ Bidirectional contextual learning for language understanding.

âœ… **DistilBERT for Emotion Classification** â€“ Build and fine-tune a lightweight Transformer.

âœ… **Basics of GPT Models** â€“ Learn how Generative Transformers work and generate text.

âœ… **Fine-Tuning Pretrained Transformers** â€“ Adapt powerful models to custom tasks.

âœ… **Prompt Engineering** â€“ Design inputs that steer LLM responses effectively.

âœ… **LLM Deployment & QA App** â€“ Explore the QueryMate demo and real-world applications.

---

## ðŸ“‚ Open in Google Colab

Click the button below to run the notebook interactively in **Google Colab**:

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PKhosravi-CityTech/ML15AI-CUNY/blob/main/Week11/Week11.ipynb)

âœ… **Interactive coding â€” no installation needed.**

âœ… **Fine-tune BERT-based models and deploy Transformer-powered apps.**

---

## ðŸŽ¥ Additional Learning Resources

Click the links below to **watch the YouTube lectures for Week 11**:

### ðŸ”¹ Transformer Architecture & Attention

ðŸ“Œ **[Watch: Transformer Neural Networks](https://youtu.be/zxQyTK8quyY?si=cvKJPARvXJgYyswj)**

ðŸ“Œ **[Watch: Attention Mechanism Works in Transformer](https://youtu.be/KMHkbXzHn7s?si=V_-UD3Bkwcnybbp6)**

ðŸ“Œ **[Watch: Attention in Transformers](https://youtu.be/eMlx5fFNoYc?si=b1opiUlE2E7WPteT)**

### ðŸ”¹ Large Language Models (LLMs)

ðŸ“Œ **[Watch: Transformers (How LLMs Work)](https://youtu.be/wjZofJX0v4M?si=4EdXFEqLRdJclfuz)**

ðŸ“Œ **[Watch: How Might LLMs Store Facts](https://youtu.be/9-Jl0dxWQs8?si=Ru8VQ-0ASxmJ6NKx)**

### ðŸ”¹ BERT & GPT

ðŸ“Œ **[Watch: BERT Neural Network](https://youtu.be/xI0HHN5XKDo?si=AfjBD8brytPRcaUH)**

ðŸ“Œ **[Watch: GPT - Explained](https://youtu.be/3IweGfgytgY?si=G8Xo9tvpivhTQlIb)**

### ðŸ”¹ Prompt Engineering & Applications

ðŸ“Œ **[Watch: Prompt Engineering](https://youtu.be/1c9iyoVIwDs?si=-PNdqsAosxsH0Cy7)**

ðŸ“Œ **[Watch: Microsoft Copilot Tutorial](https://youtu.be/lGwjvaAFjzk?si=GRvDQgg0wUYAtn8T)**

### ðŸ”¹ Bonus: Vision Transformers & Object Detection

ðŸ“Œ **[Watch: Vision Transformer](https://youtu.be/j3VNqtJUoz0?si=15a9xlMooXEiSw_W)**

ðŸ“Œ **[Watch: SegFormer](https://youtu.be/cgq2d_HkfnM?si=Vs858jsbKKGRgJT7)**

ðŸ“Œ **[Watch: YOLO Algorithm](https://youtu.be/9s_FpMpdYW8?si=_FdBVEN0dYBIeA7-)**

ðŸ“Œ **[Watch: How YOLO Object Detection Works](https://youtu.be/svn9-xV7wjk?si=sJvwS9mRCqsKH60H)**

---

## âœ… Next Steps

ðŸ“Œ **Run the notebook and fine-tune DistilBERT for emotion classification.**

ðŸ“Œ **Explore how Transformers outperform RNNs on sequence modeling.**

ðŸ“Œ **Experiment with prompt design to optimize LLM outputs.**

ðŸ“Œ **Try modifying hyperparameters for fine-tuning BERT-based models.**

ðŸ“Œ **Deploy a simple QA app using an LLM and test real-world queries.**

ðŸš€ Happy Learning! ðŸ˜ŠðŸ”¥

